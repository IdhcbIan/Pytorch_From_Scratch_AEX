{"cells":[{"cell_type":"markdown","source":["# MNIST Database MLP optimization with Numerical Methods!"],"metadata":{"id":"r-QHhKKsgeLe"}},{"cell_type":"markdown","source":["## Getting the data from the Built in MNIST Data set in tensorflow Module"],"metadata":{"id":"8CDzH2jLgueI"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","\n","\n","def load_and_preprocess_mnist():\n","    # Carregando as Imagens\n","    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()   # Dataset do Tensorflow\n","\n","    # Normalizando as Imagens...\n","    threshold = 128\n","    train_images_flattened = np.where(train_images > threshold, 1, 0).reshape(train_images.shape[0], -1)\n","    test_images_flattened = np.where(test_images > threshold, 1, 0).reshape(test_images.shape[0], -1)\n","\n","    return (train_images_flattened, train_labels)  # Retornando array Principal\n","\n","# Exemplo de Uso...\n","(train_images_flattened, train_labels) = load_and_preprocess_mnist()\n","\n","\n"],"metadata":{"id":"FUqllZsIgs7h","executionInfo":{"status":"ok","timestamp":1717635672407,"user_tz":180,"elapsed":5868,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"51fb9259-8c76-4787-b1ee-e0c92d8b2a8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"code","source":["\n","# Example: Print the first flattened image and its label\n","#print(\"First training image (flattened):\", train_images_flattened[200])\n","#n = int(input(\"Enter a number of the index up to 60k: \"))\n","#print(\"Label of the first training image:\", train_labels[n])\n","print(\"----------------------------------------\")\n","#print(f\"The data set is {len(train_images_flattened)} long:\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"194QtatkhC4Q","executionInfo":{"status":"ok","timestamp":1717635672407,"user_tz":180,"elapsed":4,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"d2ce7e6e-517b-4eff-bf8c-913485b4b6ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------\n"]}]},{"cell_type":"markdown","source":["# ---------------------------------------------------------------------"],"metadata":{"id":"4iI3y_ijg3x_"}},{"cell_type":"markdown","source":["## Making a Pygame Grid That Reconstruct the Image!"],"metadata":{"id":"58WYTuFQhSIv"}},{"cell_type":"markdown","source":["# ---------------------------------------------------------------------"],"metadata":{"id":"ypAbCGHYhhzY"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # GPU\n","\n","xs = [torch.tensor(x, dtype=torch.double, device=device) for x in train_images_flattened]\n","xs = torch.stack(xs)\n","ys = torch.tensor(train_labels, dtype=torch.long, device=device)\n","\n","\n","class Brein(nn.Module):\n","    def __init__(self):\n","        super(Brein, self).__init__()\n","        self.fc1 = nn.Linear(28*28, 512)   # wn * xn + bn  - camada Linear (28*28)in -> 512 neutonios\n","        self.relu = nn.ReLU()              # Funcao ReLu de Ativacao\n","        self.fc2 = nn.Linear(512, 10)      # Camada Linear - (512)in -> 10 out\n","\n","    def forward(self, x):   # Foward Pass\n","        x = self.fc1(x)     # Passando nas Respectivas Camadas!!\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","def train_model(train_data, train_labels, model, criterion, optimizer, epochs=20, batch_size=128, tol=10e-3):\n","\n","    # Convertendo Dados Para Tensors e carregando em GPU\n","    train_data = torch.tensor(train_data, dtype=torch.float32, device=device)\n","    train_labels = torch.tensor(train_labels, dtype=torch.long, device=device)\n","    train_dataset = TensorDataset(train_data, train_labels)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","    # Training loop\n","    big_loop = 0\n","    #for loop in range(big_loop):\n","    mode = 0\n","\n","    loss = 1000   # Inicializando Loss...(condicao do loop)\n","    while loss > tol:\n","        for data, labels in train_loader:\n","            optimizer.zero_grad()    # Grad = 0\n","            outputs = model(data)    # Foward pass\n","            loss = criterion(outputs, labels)    # Loss function ...\n","            loss.backward()\n","            optimizer.step()\n","        print(f'Iteration {big_loop+1}, Loss: {loss.item()}')\n","\n","        big_loop += 1\n","    return model\n","\n","# Initialize the model\n","model = Brein().to(device)\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","# Prepare your MNIST data\n","(train_images_flattened, train_labels) = load_and_preprocess_mnist()\n","\n","# Train the model\n","trained_model = train_model(train_images_flattened, train_labels, model, criterion, optimizer, epochs=20, tol=10e-8)\n","\n","# Function to predict the digit\n","def predict_digit(image, model):\n","    image = torch.tensor(image, dtype=torch.float32)\n","    outputs = model(image.unsqueeze(0))  # Add batch dimension\n","    _, predicted = torch.max(outputs, 1)\n","    return predicted.item()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J2_Aa8Xi2wCH","executionInfo":{"status":"ok","timestamp":1717635776495,"user_tz":180,"elapsed":104091,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"d2190428-9e98-4b72-cec6-ea3ea7c46870"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 1, Loss: 0.2534589469432831\n","Iteration 2, Loss: 0.16589994728565216\n","Iteration 3, Loss: 0.13893385231494904\n","Iteration 4, Loss: 0.1037982702255249\n","Iteration 5, Loss: 0.03833826258778572\n","Iteration 6, Loss: 0.0632224977016449\n","Iteration 7, Loss: 0.02839057147502899\n","Iteration 8, Loss: 0.010263952426612377\n","Iteration 9, Loss: 0.0161778274923563\n","Iteration 10, Loss: 0.0018627290846779943\n","Iteration 11, Loss: 0.018230142071843147\n","Iteration 12, Loss: 0.0016934688901528716\n","Iteration 13, Loss: 0.002214412670582533\n","Iteration 14, Loss: 0.023281188681721687\n","Iteration 15, Loss: 0.00586911803111434\n","Iteration 16, Loss: 0.001206003944389522\n","Iteration 17, Loss: 0.0003790329210460186\n","Iteration 18, Loss: 0.0004245871677994728\n","Iteration 19, Loss: 0.00016722333384677768\n","Iteration 20, Loss: 0.00011454011109890416\n","Iteration 21, Loss: 4.266729229129851e-05\n","Iteration 22, Loss: 0.00042301148641854525\n","Iteration 23, Loss: 8.202128083212301e-05\n","Iteration 24, Loss: 9.974862769013271e-05\n","Iteration 25, Loss: 3.10241048282478e-05\n","Iteration 26, Loss: 0.00010773597023217008\n","Iteration 27, Loss: 0.007691239472478628\n","Iteration 28, Loss: 0.009368189610540867\n","Iteration 29, Loss: 0.0019563438836485147\n","Iteration 30, Loss: 0.00023345182125922292\n","Iteration 31, Loss: 0.00015589479880873114\n","Iteration 32, Loss: 0.00011989735503448173\n","Iteration 33, Loss: 9.887814667308703e-05\n","Iteration 34, Loss: 8.99327642400749e-05\n","Iteration 35, Loss: 0.00017428710998501629\n","Iteration 36, Loss: 7.520622602896765e-05\n","Iteration 37, Loss: 9.776026854524389e-05\n","Iteration 38, Loss: 3.793453288380988e-05\n","Iteration 39, Loss: 4.0057693695416674e-05\n","Iteration 40, Loss: 2.7134012270835228e-05\n","Iteration 41, Loss: 2.6996365704690106e-05\n","Iteration 42, Loss: 7.33186534489505e-05\n","Iteration 43, Loss: 2.7760243028751574e-05\n","Iteration 44, Loss: 1.925923925227835e-06\n","Iteration 45, Loss: 1.3618250704894308e-05\n","Iteration 46, Loss: 9.687242709333077e-06\n","Iteration 47, Loss: 6.731141638738336e-06\n","Iteration 48, Loss: 1.1698860362230334e-05\n","Iteration 49, Loss: 5.381658411351964e-06\n","Iteration 50, Loss: 2.334466216780129e-06\n","Iteration 51, Loss: 3.3650303521426395e-06\n","Iteration 52, Loss: 3.132875463052187e-06\n","Iteration 53, Loss: 1.2839636838180013e-06\n","Iteration 54, Loss: 1.5745348491691402e-06\n","Iteration 55, Loss: 1.8228901126349228e-06\n","Iteration 56, Loss: 0.006078845355659723\n","Iteration 57, Loss: 0.00013150986342225224\n","Iteration 58, Loss: 1.9148765204590745e-05\n","Iteration 59, Loss: 0.00011720271868398413\n","Iteration 60, Loss: 6.920220766915008e-05\n","Iteration 61, Loss: 1.2569288628583308e-05\n","Iteration 62, Loss: 2.8223346362210577e-06\n","Iteration 63, Loss: 8.183506906789262e-06\n","Iteration 64, Loss: 2.5144341634586453e-05\n","Iteration 65, Loss: 6.855399533378659e-06\n","Iteration 66, Loss: 1.1452495527919382e-05\n","Iteration 67, Loss: 7.496033958886983e-06\n","Iteration 68, Loss: 1.0863779607461765e-05\n","Iteration 69, Loss: 2.7056646558776265e-06\n","Iteration 70, Loss: 1.1498493677208899e-06\n","Iteration 71, Loss: 6.808921170886606e-06\n","Iteration 72, Loss: 6.213416781974956e-06\n","Iteration 73, Loss: 3.5959467368229525e-06\n","Iteration 74, Loss: 7.388393328255916e-07\n","Iteration 75, Loss: 5.732708359573735e-06\n","Iteration 76, Loss: 1.0144993893845822e-06\n","Iteration 77, Loss: 1.5285831977962516e-06\n","Iteration 78, Loss: 3.539012425335386e-07\n","Iteration 79, Loss: 9.611069344828138e-07\n","Iteration 80, Loss: 5.662378157467174e-07\n","Iteration 81, Loss: 4.5696594952460146e-07\n","Iteration 82, Loss: 1.373375653201947e-06\n","Iteration 83, Loss: 2.9926391675871855e-07\n","Iteration 84, Loss: 7.810642159711279e-07\n","Iteration 85, Loss: 5.165692300579394e-07\n","Iteration 86, Loss: 1.1300037527917084e-07\n","Iteration 87, Loss: 2.1979178654873976e-07\n","Iteration 88, Loss: 1.2045079245126544e-07\n","Iteration 89, Loss: 1.5025284483272117e-07\n","Iteration 90, Loss: 1.7012122555115639e-07\n","Iteration 91, Loss: 1.6267080127363442e-07\n","Iteration 92, Loss: 2.607702498380604e-08\n"]}]},{"cell_type":"code","source":["# Testando\n","image = xs[0] # Primeira Imagem do banco de Dados\n","predicted_digit = predict_digit(image, trained_model)\n","print(f'Predicted Digit: {predicted_digit}')\n","print(f'Predicted Digit: {train_labels[0]}')"],"metadata":{"id":"zJGTJLksJ5Zi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717635776495,"user_tz":180,"elapsed":11,"user":{"displayName":"ian bezerra","userId":"05417333999231090698"}},"outputId":"5b4e6503-efd1-4584-b480-37454a526828"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Digit: 5\n","Predicted Digit: 5\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-018f982367c9>:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  image = torch.tensor(image, dtype=torch.float32)\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'mnist_model.pth')"],"metadata":{"id":"JwZpRv4T6R0a"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}