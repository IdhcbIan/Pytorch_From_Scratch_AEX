# AULA 1 - INTRODUÇÃO
# JAN/2026

                          
█▀█ █▀█ ▀█▀ █▀▀ █ █▀█ █▀█
█▀▄ █▄█  █  ██▄ █ █▀▄ █▄█

Já na antiguidade grega, as pessoas sonhavam em criar máquinas que pensam. No mito de Pigmaleão, ele se apaixona por uma estátua que esculpe, a qual chama de Galateia, e a deusa Afrodite dá-lhe vida. Há também a figura mitológica "Talos", uma estátua de bronze que supostamente defendia a ilha de Creta.

Quando computadores primeiro apareceram, nos anos 40, pessoas passaram a especular se ELES, futuramente, tornariam-se inteligentes algum dia.

Atualmente, a inteligência artificial - IA - construída em cima deles é um campo muito ativo, com várias aplicações práticas e linhas de pesquisa. Software inteligente automatiza tarefas laborais, entende fala e imagens e ajuda em diagnósticos médicos, por exemplo.

Muitos dos sucessos iniciais de IA se deram em ambientes relativamente formais e estéreis e não requeririam que o computador tivesse muito conhecimento sobre o mundo. Por exemplo, o Deep Blue da IBM, um computador arquitetado para jogar xadrez, venceu em 1997 do então campeão do mundo e lenda do jogo, Garry Kasparov. O xadrez é um mundo muito simples de se descrever, com apenas 64 posições e 32 peças de movimento rígido e regrado.
	Construir um robô mestre enxadrista é um grande mérito, porém o desafio não é devido a alguma dificuldade em descrever o conjunto das peças de xadrez e dos movimentos permitidos pelo jogo. Xadrez pode ser descrito completamente a um computador por uma lista muito enxuta de regras formais.
	Ironicamente, tarefas abstratas, formais e mentalmente desgastantes para pessoas estão entre as mais fáceis para um computador, entretanto, apenas recentemente estão chegando a par com nossa capacidade de reconhecer objetos e fala. O dia a dia de uma pessoa requer tremendo conhecimento sobre o mundo. Muito deste conhecimento é subjetivo e intuitivo e, portanto, difícil de articular de maneira formal. Computadores precisam captar este mesmo conhecimento para agirem de forma inteligente.

Isso é um dos grandes desafios da inteligência artifical moderna.

Uma primeira abordagem proposta para a resolução de problemas intuitivos foi codificar conhecimento sobre o mundo diretamente em uma linguagem formal de programação, o que não tem produzido grandes resultados. Uma das tentativas mais famosas é o projeto Cyc, iniciado em 84, escrito na linguagem CycL e munido de um banco de afirmações imenso, todas escritas por pessoas. O Cyc foi incapaz de compreender uma história sobre uma pessoa chamada Fred fazendo a barba pela manhã. A IA detectou uma inconsistência na história. Sabia que pessoas não possuem partes elétricas, entretanto, como Fred segurava um barbeador ELÉTRICO, imaginava que a entidade "FredWhileShaving", ou, aproximadamente em português, "FredAparandoSuaBarba", continha partes elétricas. Portanto, indagou se Fred ainda era uma pessoa enquanto se barbeava.

A dificuldade em se programar a mão conhecimento sugere que IAs precisam da habilidade de adquirir conhecimento por conta, extraindo padrões de dados brutos. Tal habilidade leva o nome de "Aprendizado de Máquina" ou, em inglês, "Machine Learning". Essa proposta, por sua vez, tem melhorado sim a capacidade de computadores de fazerem escolhas subjetivas.

Entendamos mais precisamente este tal "aprendizado" por meio de um exemplo de uma máquina na esfera do mercado imobiliário: Nessa situação hipotética, suponha que temos uma planilha listando a venda de vários imóveis. Nela, além do preço de venda, contém também a área, o número de cômodos e o número de dias que cada imóvel passou no mercado até ser vendido.
	Nosso objetivo aqui é construir uma máquina que consiga aprender de todas essas vendas para sugerir o preço de novas listagens que faremos. Para tanto, definiremos algumas "features", do inglês, "características" ou "parâmetros", que nossa máquina terá, e, crucialmente, cujos valores são variáveis. Isso pois queremos que os nossos dados brutos ditem seus valores, não um ser-humano.
	Para começar, escolheremos um parâmetro de área e outro relativo ao número de cômodos. A ideia é que eles sinalizem quanto a área e o número de cômodos pesam na valoração de um imóvel. Não elegeremos um parâmetro relativo aos dias que o imóvel passa no mercado até ser vendido, pois essa informação só existe após a venda, não no momento que anunciaremos uma nova casa. Por fim, elegeremos um parâmetro adicional "de partida", por assim dizer, pensando que todo imóvel, independentemente do tamanho da construção ou da quantidade de quartos, tem um valor base, do terreno ou da empreita de sua construção. Note que os parâmetros da máquina não precisam espelhar os dados!
	O cálculo que nossa máquina fará para estimar o preço de um imóvel novo na realidade não é nada complicado. Basta mutiplicar a área e o número de cômodos pelos seus respectivos parâmetros e somá-los ao parâmetro de partida. Isso nos dá nossa estimativa. A parte crucial aqui será qual valor numérico escolher para cada parâmetro. Fundamentaremos essa escolha por nossos dados.
	Antes, porém, vale mostrar que essa equação pode ser expressa na forma de um grafo. É bom já criarmos agora um pouco de familiaridade com essa notação equivalente, pois usaremos grafos para representar redes neurais, o tema principal deste curso, junto com aprendizado profundo. Saliento novamente que o dado de "dias no mercado" é ignorado em nossa arquitetura de máquina.
	Com essa digressão concluída, retomemos ao ponto principal deste exemplo: os dados ditam os valores dos parâmetros de nossa máquina, ou, dito de forma mais poética, a máquina aprende dos dados.
	Neste exemplo específico, os parâmetros dependem dos dados conforme uma "regressão linear", como dizem os matemáticos. Não entraremos em detalhes do que é uma "regressão linear" e como funciona exatamente, pois não a usaremos no aprendizado profundo, mas, de forma rápida, intuitiva e um pouco grosseira, são os coeficientes que produzem o plano mais próximo de todas vendas registradas. Claro, como há um pouco de variabilidade nos preços de cada imóvel, o ajuste não será perfeito, mas, entre todos os planos, este é o melhor. Portanto, fica claro que, se o nosso banco de dados fosse outro, com uma distribuição muito diferente da desta imagem, o plano de melhor ajuste também mudaria, ou seja, nossa máquina aprenderia um outro padrão. Essa sensibilidade é o que chamamos de "aprendizado de máquina".

	Agora, tentemos aplicar "aprendizado de máquina" em outro contexto: reconhecimento de objetos para carros autônomos. Nossos dados neste caso são imagens, e imagens, por sua vez, são muitos quadradinhos, ou pixels, cada um com uma coloração uniforme. Então, se a entrada de nossa máquina é uma matriz de cores, de quais parâmetros munimos ela? Digamos que queremos reconhecer carros, que parâmetros filtram uma imagem para concluir se ela é um carro ou não? Será que deveríamos procurar rodas na imagem? Bem, como fazemos isso? É o mesmo problema, só que para um objeto um pouco menor. De toda forma, será que procuramos por pixels de tonalidades mais escuras, no formato de um círculo?
	Bem... e se a luminosidade da foto for muito baixa, e for difícil de discernir o formato circular do pneu? Ou então, e se o carro estiver em um ângulo diferente, em que o pneu não se parece circular? Ou, num caso extremo, e se não conseguimos nem ver um pneu? Como cumprimos nosso objetivo primeiro de identificar um carro?

Precisamos de uma máquina com capacidade de aprendizado mais robusto do que a que vimos no caso imobiliário. Veremos agora um tipo de máquina que não só ajusta o valor de seus parâmetros com os dados que é alimentada, mas também desenvolve seus próprios parâmetros a partir deles, sem a necessidade de uma pessoa definí-los para a máquina.

Tal máquina é a rede neural, e o aprendizado da rede neural leva o nome de "aprendizado profundo". Esse par é o cerne de nosso curso.
	O elemento atômico da rede neural é chamado de "neurônio" e é inspirado, por mais que bem distinto, nos neurônios biológicos. Discutiremos o neurônio melhor na próxima aula. Uma coleção de neurônios leva o nome de "camada". Por fim, se ligarmos algumas camadas em série, já teremos uma rede neural. Existem arquiteturas de redes neurais mais sofisticadas, mas essa é sua estrutura elementar. O aprendizado é dito "profundo" para essa máquina, pois ela possui múltiplas camadas. Inclusive, quanto mais camadas, mais capaz se torna a rede neural, mas mais custosa também.
	A ideia aqui é que cada camada seja capaz de identificar informações mais abstratas.

	Se voltarmos ao exemplo de reconhecimento de objetos, agora munidos de uma rede neural, esperamos que a primeira camada veja coleções de pixels que formam bordas, a segunda, cantos e contornos pela junção de bordas, a terceira partes de objetos, como a roda do carro e na última, venha o reconhecimento de algum objeto, baseado em suas partes.
	Vale frisar que se "abrirmos o capô" de uma rede neural e realmente observar as "features" aprendidas em cada camada, várias vezes serão interpretáveis para uma pessoa, afinal, as redes são treinadas por algoritmos matemáticos, não supervisores humanos, entretanto, sabemos que se a rede está funcionando bem, é porque, de alguma forma, seja ela legível por nós ou não, está conseguindo criar boas "features", desde as mais rudimentares, das camadas iniciais, até as mais abstratas, das camadas finais.

Com isso, concluímos nossa primeira aula. Espero que tenha ficado claro a diferença entre uma IA que faz e não faz aprendizado de máquina, e uma máquina que faz e não faz aprendizado profundo.

Por fim, é importante destacar que esta aula é um resumo em formato de slides da introdução do livro "Deep Learning", escrito em 2016 pesquisador americano Ian Goodfellow, que foi um dos primeiros funcionários da OpenAI e atualmente trabalha para a Google. As ideias aqui são crédito dele e seus co-autores, Yoshua Bengio e Aaron Courville.
